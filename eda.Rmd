---
title: "eda"
output: html_document
date: "2024-07-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#test
``` {Libraries} 

library(tidyverse)
library(dplyr)
library(gbm)
library(tree)
library(rpart)
library(caret)
library(MASS)
library(randomForest)
library(rpart.plot)
library(math)

```

Our first step is to explore our data set. The Kaggle website for the data set had relatively complete variable descriptions, as well as 

``` {r EDA Part 1}
spotify = read.csv("spotify_dataset.csv")

```

Removing rows with time_signature = 0
```{r filtering}
filtered_spotify <- 
  spotify %>% 
  filter(
    time_signature %in% c(3, 4, 5, 6, 7))

attach(filtered_spotify)

# No missing values:

sum_isna <- sum(is.na(filtered_spotify))
sum_isna


# Count duplicates:

sum(duplicated(track_id))

# Remove duplicates that have the same track_name, artists and only keep the most popular song
filtered_spotify <-
  filtered_spotify %>%
  group_by(track_name, artists) %>% 
  filter(popularity == max(popularity))
 
#Test:  
filtered_spotify %>% filter(track_name == "Run Rudolph Run")

# View duplicate track_ids
duplicates_sorted <- filtered_spotify %>%
  group_by(track_id) %>%
  filter(n() > 1) %>%
  arrange(track_id)


# Some songs have the same track_id but are in different genres

filtered_spotify <-
  filtered_spotify %>% 
  group_by(track_id) %>% 
  

```

``` {r Plotting}
plot(danceability ~ tempo)
plot(danceability, popularity)
cor(tempo, danceability)



```