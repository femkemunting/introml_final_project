---
title: "eda"
output: html_document
date: "2024-07-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#test
``` {Libraries}

library(tidyverse)
library(dplyr)
library(gbm)
library(tree)
library(rpart)
library(caret)
library(MASS)
library(randomForest)
library(rpart.plot)

```

Our first step is to explore our data set. The Kaggle website for the data set had relatively complete variable descriptions, as well as 

``` {r EDA Part 1}
spotify = read.csv("spotify_dataset.csv")

```

Removing rows with time_signature = 0
```{r filtering}
filtered_spotify <- 
  spotify %>% 
  filter(
    time_signature %in% c(3, 4, 5, 6, 7))

attach(filtered_spotify)

# No missing values:

sum_isna <- sum(is.na(filtered_spotify))
sum_isna


# Count duplicates:

sum(duplicated(track_id))

# Remove duplicates that have the same track_name, artists and only keep the most popular song
filtered_spotify <-
  filtered_spotify %>%
  group_by(track_name, artists) %>% 
  filter(popularity == max(popularity))


 
#Test:  
filtered_spotify %>% filter(track_name == "Run Rudolph Run")



# View duplicate track_ids
duplicates_sorted <- filtered_spotify %>%
  group_by(track_id) %>%
  filter(n() > 1) %>%
  arrange(track_id)

 
# Some songs have the same track_id but are in different genres

filtered_spotify <-
  filtered_spotify %>% 
  group_by(track_id) %>% 
  sample_n(1)
  
duplicates_sorted_2 <- filtered_spotify %>%
  group_by(track_id) %>%
  filter(n() > 1) %>%
  arrange(track_id)
  

```

``` {r Plotting}
plot(danceability ~ tempo)
plot(danceability, popularity)

non_quant_variables = c("track_id", "artists", "album_name", "track_name", "explicit", "track_genre")

quant_variables <-
  filtered_spotify %>% 
  select_if(is.numeric) 

quant_variables <- quant_variables[,  2:16]

cor(quant_variables)

pairs(quant_variables)

```

Linear model to see relation between variables
```{r}
spotify_lm_dataset <- filtered_spotify %>% select(-X, -track_id, -artists, -album_name, -track_name, -track_genre, -explicit)
filtered_spotify_lm <- lm(popularity ~ ., data = spotify_lm_dataset)
summary(filtered_spotify_lm)
plot(spotify_lm_dataset$danceability, spotify_lm_dataset$popularity)
```

Cross-validation
```{r}
set.seed(18)

# Hold out 20% of the data as a final validation set
train_ix = createDataPartition(quant_variables$popularity,
                               p = 0.8)

spotify_train = quant_variables[train_ix$Resample1,]
spotify_test  = quant_variables[-train_ix$Resample1,]

###########################################################################
# Setup cross-validation
###########################################################################

# Define how we're going to estimate OOS error using cross-validation

# Number of folds
kcv = 10

# I'm manually making the folds here so we can look at them, and so
# they're the same when we evaluate each method below. If you omit
# the indexOut argument below caret with make the folds behind the scenes.

cv_folds = createFolds(spotify_train$popularity,
                               k = kcv)

# This function sets up how we're going to do our training: The method for
# estimating OOS error (CV) and associated settings (here the folds we created 
# above). I'm also going to request that our final fit is determined not by
# the minimum estimated OOS RMSE but using the one standard deviation (aka
# one standard error) rule instead by specifying selectionFunction="oneSE"

fit_control <- trainControl(
  method = "cv",
  indexOut = cv_folds,
  selectionFunction="oneSE")
```

Boosting
```{r}
###########################################################################
# Boosting
###########################################################################

# Boosting, optimizing over default grid for number of trees and depth
gbmfit <- train( popularity ~ ., data = spotify_train, 
                 method = "gbm", 
                 trControl = fit_control,
                 verbose = FALSE)

# Using a custom grid
gbm_grid <-  expand.grid(interaction.depth = c(1, 2, 3, 5, 10), 
                        n.trees = c(150, 500, 1000), 
                        shrinkage = c(0.01, 0.1, 0.2),
                        n.minobsinnode = 10)

gbmfit_2 <- train(popularity ~ ., data = spotify_train, 
                 method = "gbm", 
                 trControl = fit_control,
                 tuneGrid = gbm_grid,
                 verbose = FALSE)

print(gbmfit_2)
```


