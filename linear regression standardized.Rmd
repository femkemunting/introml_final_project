---
title: "Clean_Data_Spotify"
output: html_document
date: "2024-07-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Libraries}

library(tidyverse)
library(dplyr)
library(gbm)
library(tree)
library(rpart)
library(caret)
library(MASS)
library(randomForest)
library(rpart.plot)
library(ISLR)
library(leaps)
library(glmnet)
library(ggplot2)

set.seed(1)
```

Our first step is to explore our data set. The Kaggle website for the data set had relatively complete variable descriptions, as well as

```{r EDA Part 1}
spotify = read.csv("spotify_dataset.csv")

```

Removing rows with time_signature = 0

```{r filtering}
filtered_spotify <- 
  spotify %>% 
  filter(
    time_signature %in% c(3, 4, 5, 6, 7))

attach(filtered_spotify)

# No missing values:

sum_isna <- sum(is.na(filtered_spotify))
sum_isna


# Count duplicates:

sum(duplicated(track_id))

# Remove duplicates that have the same track_name, artists and only keep the most popular song
filtered_spotify <-
  filtered_spotify %>%
  group_by(track_name, artists) %>% 
  filter(popularity == max(popularity))


 
#Test:  
filtered_spotify %>% filter(track_name == "Run Rudolph Run")



# View duplicate track_ids
duplicates_sorted <- filtered_spotify %>%
  group_by(track_id) %>%
  filter(n() > 1) %>%
  arrange(track_id)

 
# Some songs have the same track_id but are in different genres

filtered_spotify <-
  filtered_spotify %>% 
  group_by(track_id) %>% 
  sample_n(1)
  
duplicates_sorted_2 <- filtered_spotify %>%
  group_by(track_id) %>%
  filter(n() > 1) %>%
  arrange(track_id)
  

# Convert mode and key to factors and turn genre into a binary variable (pop or not pop), make some other categorical/ one-hot encoded variables. Change duration_ms into minutes, rounded to one decimal place
regular_data <-
  filtered_spotify %>% 
  mutate(mode = factor(mode),
         key = factor(key),
         explicit = factor(explicit, levels = c("True", "False")),
         track_genre = factor(ifelse(grepl("pop", track_genre, ignore.case = TRUE), "Pop", "Not_Pop"), levels = c("Pop", "Not_Pop")),
         )

tempo_bottom_third = min(tempo) + (max(tempo) - min(tempo)) / 3
tempo_top_third = max(tempo) - (max(tempo) - min(tempo)) / 3
  
one_hot_encoded <-
  filtered_spotify %>% 
  mutate(mode = factor(mode),
         key = factor(key),
         explicit = factor(explicit, levels = c("True", "False")),
         track_genre = factor(ifelse(grepl("pop", track_genre, ignore.case = TRUE), "Pop", "Not_Pop"), levels = c("Pop", "Not_Pop")),
         instrumentalness = factor(ifelse(instrumentalness >= 0.2, "Instrumental", "Not_Instrumental"), levels = c("Instrumental", "Not_Instrumental")),
         spoken_word = factor(ifelse(speechiness >= 0.66, "yes", "no"), levels = c("yes", "no")),
         average_speech = factor(ifelse((speechiness < 0.66) & (speechiness >= 0.33), "yes", "no"), levels = c("yes", "no")),
         no_speech = factor(ifelse(speechiness < 0.33, "yes", "no"), levels = c("yes", "no")),
         slow = factor(ifelse(tempo <= tempo_bottom_third, "slow", "not_slow")),
    medium = factor(ifelse(tempo > tempo_bottom_third & tempo < tempo_top_third, "medium", "not_medium"), levels = c("medium", "not_medium")),
    fast = factor(ifelse(tempo >= tempo_top_third, "fast", "not_fast"), levels = c("fast", "not_fast"))
         )

regular_data <- subset(regular_data, select = -c(X, track_id, track_name, album_name, artists))
one_hot_encoded <- subset(one_hot_encoded, select = -c(X, track_id, track_name, album_name, artists, speechiness, instrumentalness, tempo))


# Removing outliers from data:
regular_data <- regular_data[-c(13795, 55236, 68307), ]
one_hot_encoded <- one_hot_encoded[-c(13795, 55236, 68307), ]


# Standardize variables

regular_data <-
  regular_data %>% 
  mutate(
    across(c(popularity, duration_ms, danceability, energy, loudness, acousticness, liveness, valence, speechiness, tempo, instrumentalness), ~ (. - mean(.)) / sd(.))
  )

one_hot_encoded <-
  one_hot_encoded %>% 
  mutate(
    across(c(popularity, duration_ms, danceability, energy, loudness, acousticness, liveness, valence), ~ (. - mean(.)) / sd(.))
  )

# Citation: asked ChatGPT how to run a mutate across multiple columns

regular_data <- regular_data[sample(nrow(regular_data), 10000) , ]
one_hot_encoded <- one_hot_encoded[sample(nrow(one_hot_encoded), 10000) , ]
# Citation: https://stackoverflow.com/questions/8273313/sample-random-rows-in-dataframe

# Train-test Split

regular_train_indices <- createDataPartition(regular_data$popularity,
                               p = 0.8)
one_hot_indices<- createDataPartition(one_hot_encoded$popularity,
                               p = 0.8)


regular_train <- regular_data[regular_train_indices$Resample1,]
regular_test <- regular_data[-regular_train_indices$Resample1,]

one_hot_train <- one_hot_encoded[one_hot_indices$Resample1,]
one_hot_test <- one_hot_encoded[-one_hot_indices$Resample1,]

kcv = 10

regular_cv_folds = createFolds(regular_train$popularity,
                       k = kcv)
one_hot_cv_folds = createFolds(one_hot_train$popularity,
                       k = kcv)

regular_fit_control <- trainControl(
  method = "cv",
  indexOut = regular_cv_folds,
  selectionFunction="oneSE")

one_hot_fit_control <- trainControl(
  method = "cv",
  indexOut = one_hot_cv_folds,
  selectionFunction="oneSE")
```
Subset Regression (reg)
```{r}

# Check for missing values
sum(is.na(regular_data))

# Fit regsubsets model on the training data
regfit <- regsubsets(popularity ~ ., data = regular_train, nvmax = 30, really.big = TRUE) # nvmax adjusts number of variables # really.big = true allows for a big search

# Create a function to calculate RMSE
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2)) }

# Evaluate models on the test data
# testX views predictors
# -1 excludes the intercept column
testX <- model.matrix(popularity ~ ., regular_test) # predictor matrix
# testY compares response variable actual values vs predicted
testY <- regular_test$popularity # response vector

# Get the actual number of predictors used in the regfit object
num_predictors <- length(summary(regfit)$outmat[1,])

# Create a vector to store RMSE values for each model
# rep() repeats vector x 
rmse_values <- rep(NA, num_predictors) 

# Loop over each model size from 1 to number of predictors
for (i in 1:num_predictors) {
  # Get the coefficients of the i-th model from the regsubsets result
  # 'id = i' specifies which model to extract, starting from 1 until id = nvmax
  coef_i <- coef(regfit, id = i)
  
  # Predict the response variable using the i-th model coefficients
  # We select only the columns corresponding to the predictors included in the i-th model
    # '%*%' is the matrix multiplication operator in R, calculates predicted values.
  pred_i <- testX[, names(coef_i)] %*% coef_i
  
  # Calculate the RMSE for the i-th model's predictions on the test data
  rmse_values[i] <- rmse(testY, pred_i)
  
  # Print (concatenate) the details of the i-nth model
  cat("\nModel with", i, "predictors\n")
  cat("Predictors:", names(coef_i), "\n")
  cat("RMSE:", rmse_values[i], "\n")
}

# Identify the model with the lowest RMSE
best_model_index <- which.min(rmse_values)
best_model_rmse <- rmse_values[best_model_index]

# Output the best model index and its RMSE
print(paste("Best model index:", best_model_index))
print(paste("Best model RMSE:", best_model_rmse))

# Get the coefficients of the best model
best_model_coef <- coef(regfit, id = best_model_index)
print("Coefficients of the best model:")
print(best_model_coef)

# Plotting
rmse_df <- data.frame(
  Model = 1:num_predictors,
  RMSE = rmse_values
)

# Plot the RMSE values
ggplot(rmse_df, aes(x = Model, y = RMSE)) +
  geom_line() +
  geom_point() +
  labs(title = "RMSE vs. Number of Predictors",
       x = "Number of Predictors",
       y = "RMSE") +
  theme_minimal()


```
Shrinkage lasso and ridge (reg)
```{r}
# Prepare the data
trainX <- model.matrix(popularity ~ ., regular_train)[, -1] # Predictor matrix for training
trainY <- regular_train$popularity # Response vector for training
testX <- model.matrix(popularity ~ ., regular_test)[, -1] # Predictor matrix for testing
testY <- regular_test$popularity # Response vector for testing

# Fit a Lasso regression model
lasso_fit <- cv.glmnet(trainX, trainY, alpha = 1) # alpha = 1 for Lasso
lasso_pred <- predict(lasso_fit, s = "lambda.min", newx = testX)
lasso_rmse <- sqrt(mean((testY - lasso_pred)^2))
lasso_coef <- coef(lasso_fit, s = "lambda.min")
print(lasso_coef)
# Lasso sets some variable coefficients to 0 (effectively removing them)

# Fit a Ridge regression model
ridge_fit <- cv.glmnet(trainX, trainY, alpha = 0) # alpha = 0 for Ridge
ridge_pred <- predict(ridge_fit, s = "lambda.min", newx = testX)
ridge_rmse <- sqrt(mean((testY - ridge_pred)^2))
ridge_coef <- coef(ridge_fit, s = "lambda.min")
print(ridge_coef)
# Ridge shrinks the coefficients but never removes the variables (zero)

# Print the RMSE for both models
print(paste("Lasso RMSE:", lasso_rmse))
print(paste("Ridge RMSE:", ridge_rmse))


# Lasso produces slightly higher rmse
# Lasso tends to perform better when a small number of predictors have a strong effect on Y


# Create a data frame for plotting
rmse_methods_df <- data.frame(
  Method = c("Subset Selection", "Lasso", "Ridge"),
  RMSE = c(best_model_rmse, lasso_rmse, ridge_rmse)
)

# Plot the RMSE values for different methods with a zoomed-in view
ggplot(rmse_methods_df, aes(x = Method, y = RMSE)) +
  geom_bar(stat = "identity") +
  labs(title = "RMSE Comparison of Different Methods",
       x = "Method",
       y = "RMSE") +
  theme_minimal() +
  scale_y_continuous(limits = c(0, max(rmse_methods_df$RMSE) * 1.1), labels = scales::number_format(accuracy = 0.01)) +
  geom_text(aes(label = sprintf("%.2f", RMSE)), vjust = -0.5, size = 3.5) +
  coord_cartesian(ylim = c(min(rmse_methods_df$RMSE) - 0.1, max(rmse_methods_df$RMSE) + 0.1)) # zooms in on y-
```

